{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work, we scrape a stock website for some time every 60 seconds and store the table data in pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes the fetched page, and scrapes its content using the Soup call. It returns the soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    page_fetch = requests.get(url)\n",
    "    soup = BeautifulSoup(page_fetch.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the url where the resource is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an empty multi-dimensional list of 51 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray = [[None]] * 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsoup = get_soup(url)\\ntable = soup.find(\\'table\\', {\"class\":\"tbldata14 bdrtpg\"}) \\ntable_body = table.find(\\'tbody\\') # Entering table body\\nrows = table.find_all(\\'tr\\') # Table rows\\nmake_table = []\\none_row_data = []\\nrow_count = 0\\nfor row in rows:  # For each row\\n    row_count += 1\\n    columns = row.find_all(\\'td\\', {\"class\":\"brdrgtgry\"}) # Columns for each row\\n    for i in columns:\\n        one_row_data.append(i.text.strip())\\n    make_table.append(one_row_data)\\n    print(make_table)\\nfor row_counter in range(row_count):\\n    ndarray[row_counter].append(make_table[row_counter])\\nprint(ndarray)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrap_and_store_repeatedly():\n",
    "    soup = get_soup(url) # Fetch url resource\n",
    "    table = soup.find('table', {\"class\":\"tbldata14 bdrtpg\"}) # Find the stock data table\n",
    "    table_body = table.find('tbody') # Entering table body\n",
    "    rows = table.find_all('tr') # Table rows\n",
    "    make_table = [] # One company at a time, one scrape at a time\n",
    "    one_row_data = [] # columns for one company\n",
    "    row_count = 0\n",
    "    for row in rows:  # For each row\n",
    "        row_count += 1\n",
    "        columns = row.find_all('td', {\"class\":\"brdrgtgry\"}) # Columns for each row\n",
    "        for i in columns:\n",
    "            one_row_data.append(i.text.strip()) # Columns for one company\n",
    "        make_table.append(one_row_data) # One company at a time, one scrap at a time\n",
    "        print(make_table)\n",
    "    for row_counter in range(row_count):\n",
    "        # One time scraping complete, results stored in ndarray, this array will get appended to various iterations\n",
    "        ndarray[row_counter].append(make_table[row_counter])\n",
    "    print(ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below method will keep scraping by calling the above method every 60 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstarttime=time.time()\\nwhile True:\\n  scrap_and_store_repeatedly()\\n  time.sleep(60.0 - ((time.time() - starttime) % 60.0))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starttime=time.time()\n",
    "while True:\n",
    "  scrap_and_store_repeatedly()\n",
    "  time.sleep(60.0 - ((time.time() - starttime) % 60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert ndarray to numpy array so that it can ultimately be stored as pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = np.asarray(ndarray) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in numpy_data:\\n    print(i)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in numpy_data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One DataFrame stores data for one company with multiple scrapings with time. So we have as many DataFrames as there is a number of <br/>companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_data_frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending numpy arrays to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(numpy_data)):\\n    list_of_data_frames.append(pd.DataFrame(data=numpy_data[i], columns=[\"column1\", \"column2\", \"column3\"]))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(numpy_data)):\n",
    "    list_of_data_frames.append(pd.DataFrame(data=numpy_data[i], columns=[\"column1\", \"column2\", \"column3\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in list_of_data_frames:\\n    print(i)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in list_of_data_frames:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
